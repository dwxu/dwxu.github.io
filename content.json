{"meta":{"title":"Dongwu Xu","subtitle":"Blog","description":null,"author":"Dongwu Xu","url":"http://www.dwxu.me"},"pages":[{"title":"关于我","date":"2018-05-21T14:11:10.068Z","updated":"2018-05-21T14:11:10.067Z","comments":false,"path":"about/index.html","permalink":"http://www.dwxu.me/about/index.html","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132&#123; \"name\": \"Dongwu Xu\", \"age\": 24, \"gender\": \"男\", \"address\": \"广东省广州市\", \"education\": \"本科\", \"profession\": \"计算机\", \"experience\": \"4年\", \"github\": \"https://github.com/dwxu\", \"blog\": \"http://www.dwxu.me\", \"email\": \"im.xudongwu@gmail.com\", \"skill\":[ [\"Java\"], [\"Spring\", \"Mybatis\", \"Apache Storm\"], [\"Html\", \"Javascript\", \"JQuery\", \"CSS\"], [\"Redis\", \"Kafka\"], [\"MySQL\", \"MariaDB\"], [\"Git\", \"SVN\"], [\"Maven\", \"Ant\"] ], \"os\": [\"masOS\", \"IOS\", \"Windows\", \"Linux\"], \"devTool\":[ [\"IntelliJ IDEA\", \"Eclipse\"], [\"Chrome DevTools\", \"Fiddler\"], [\"Git Bash\", \"TortoiseSVN\"], [\"Navicat\"], [\"Xshell\", \"Xftp\", \"SecureCRT\"] ]&#125;"},{"title":"友情链接","date":"2018-05-13T15:17:53.082Z","updated":"2018-05-13T15:17:53.082Z","comments":true,"path":"links/index.html","permalink":"http://www.dwxu.me/links/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-05-13T15:17:53.082Z","updated":"2018-05-13T15:17:53.082Z","comments":false,"path":"categories/index.html","permalink":"http://www.dwxu.me/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-05-13T15:17:53.083Z","updated":"2018-05-13T15:17:53.083Z","comments":false,"path":"tags/index.html","permalink":"http://www.dwxu.me/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"数据库复制（主从同步）延迟问题分析及处理过程","slug":"MariaDB-Replication-Delay","date":"2018-06-07T15:43:27.000Z","updated":"2018-06-07T16:27:35.264Z","comments":true,"path":"2018/06/07/MariaDB-Replication-Delay/","link":"","permalink":"http://www.dwxu.me/2018/06/07/MariaDB-Replication-Delay/","excerpt":"","text":"一、前言&emsp;&emsp;由于我们的产品数据量非常大，写库十分频繁，每日大概有 8 - 9 亿的数据写入数据库。使用中间件 Mycat 做分片管理 18 个数据库实例下的多个 DB，考虑减轻数据集中写入的压力，使用了主主同步/复制的模式。&emsp;&emsp;随着时间的推移，数据库之间的同步延迟越来越大，导致从数据同步延迟的库中查询到的数据不实时，影响比较大，亟待解决。&emsp;&emsp;我们实际使用的数据库为 MariaDB，MySQL 源代码的一个分支，大部分特性相同。 二、问题分析1. 数据库同步/复制过程 Master 在每个事务更新数据完成之前，会在 Binlog 中记录这些改变，数据库将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，Master通知存储引擎提交事务; Slave 的 I/O 线程将 Master 的 Binlog 拷贝到它自己的中继日志； Slave 的 SQL Slave Thread 线程从中继日志读取事件，并重放其中的事件而更新slave的数据，使其与master中的数据一致，即完成同步。 &emsp;&emsp;从以上过程可以看出，复制过程有一个很重要的限制，即复制在 Slave 上是串行化的，也就是说 Master 上的并行更新操作不能在 Slave 上并行操作。即使并发进行数据复制，线程数也是有限的。因此，事务在 Slave 上的执行效率没有 Master 那么高，这一点是无法避免的。 2. 数据库系统参数 日志写入磁盘策略（InnoDB 引擎）： innodb_flush_log_at_trx_commit：日志写入/刷新策略； sync_binlog：日志写入磁盘策略； 同步/复制线程数： slave_parallel_threads 组提交（MariaDB）： binlog_commit_wait_usec：延迟指定时间（毫秒）提交事务； binlog_commit_wait_count：达到指定个数（事务）立即提交事务； 3. 程序层面 我们的程序数据入库周期为 10 分钟，期间使用内存做缓存和聚合； 不存在大事务（运行时间比较长，操作的数据比较多），实际上每次提交的事务仅包含一条SQL 语句，写入合并结果数据到数据库； 由于按数据库主键进行数据合并后再入库，锁冲突/竞争导致延迟过大的可能不大； 4. 网络 当主从数据库服务器之间的带宽被占满、网络延迟很大的情况下，可能导致 Master 上的 Binlog 没有全量传输到 Slave，导致延迟； 线上排查发现 Slave 的 I/O 线程近乎实时地将 Master 的 Binlog 拷贝过来了，因此基本排除网络因素导致的延迟； 5. 机器性能 主从数据库服务器差异：CPU/内存/磁盘等配置一致； 从数据库服务器负载： 通过 top 指令分析系统运行各个进程的资源占用状况，没有明显的异常； 通过中间件 MyCat 分片管理，读写比较均匀地落到每个数据库实例上，不至于让某些实例负载过高； 单独分析服务器 CPU、内存均无异常，分析磁盘：&emsp;&emsp;可以看出，sde 磁盘（多个数据库实例目录所在盘） I/O 十分频繁，100% 的时间都在进行读写操作，当 I/O 的响应跟不上数据库同步读写的需求时，即成为瓶颈。 三、处理过程1. 参数调优 innodb_flush_log_at_trx_commit 设置为 2 配合 sync_binlog 参数（100），每写入 100 次二进制日志后才将日志刷入磁盘，存在数据丢失可能（系统崩溃/断电）但写入性能较好； slave_parallel_threads 配置为 16（需评估服务器硬件资源情况），即开启 16 个线程进行数据同步，提高复制并发度； binlog_commit_wait_usec 设置为 100000（毫秒），binlog_commit_wait_count 设置为 20，接受一定程度的数据延迟； 2. 程序优化 需要结合具体业务考虑优化方案，如数据缓存、批量入库等； 3. 服务器性能提升&emsp;&emsp;从上面的服务器性能分析中，我们怀疑磁盘可能是瓶颈（每秒I/O达100%）所在，因此做了如下操作进行验证： 在其中一台运行了 5 个数据库实例的服务器上，逐一暂停实例运行，最终发现当降到只有 2 个实例同时运行时，磁盘 I/O 有明显下降，数据库的同步延迟在快速的追回，因此可以确定磁盘的 I/O 能力是瓶颈所在。因此我们在服务器上追加了几块性能比较好的磁盘（10K RPM），并将数据库实例迁移到不同盘上，减轻单个盘的 I/O 压力，Linux 系统下操作过程也不是特别复杂，以存放在 /data 目录下的 mysqld_1 迁移到挂载其他磁盘的 /data1 目录下为：123456789# 暂停实例service mysqld_1 stop# 目录/数据拷贝，/data 挂载 sde 盘，/data1 挂载其他磁盘cp -a /data/mysql_1 /data1# 通过软链接的方式将 MariaDB 的实例目录指向迁移后的磁盘mv mysql_1 mysql_1.bakln -s /data1/mysql_1 mysql_1# 重启实例，正常启动即完成了实例的迁移service mysqld_1 start &emsp;&emsp;最终，磁盘 I/O 压力下降，数据库同步延迟在逐渐减少最终降到零（基本实时同步）： &emsp;&emsp;因为一些原因，最终每台服务器只追加了两块磁盘（sdf 和 sdg ），可以看到，原来 100% 读写的 sde 盘的 %util （1 秒内 I/O 操作所占的比例）也降至 75%。可通过以下指令在数据库命令行下查看主从同步的情况： 12345MariaDB [(none)]&gt; show slave status \\G;*************************** 1. row *************************** ...... Seconds_Behind_Master: 0 ...... 四、经验总结 大数据系统或数据量巨大的架构中，不适合在一台物理服务器上运行多个数据库实例，尤其都放到一块硬盘中，即使服务器总体性能很强，最终也只是造成部分资源的过剩和浪费，比如我们的服务器瓶颈在磁盘I/O，CPU 和 内存资源相对过剩，尤其是 CPU 90% 以上的时间处于空闲状态； 评估好数据库读写压力情况，慎用主主（互为主从关系）同步架构，存在循环同步判断和过滤开销； 排查问题时优先从 服务器资源 层面寻找瓶颈所在，进而分析 数据库系统 和 程序 层面的隐患所在和优化空间。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.dwxu.me/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.dwxu.me/tags/MySQL/"},{"name":"MariaDB","slug":"MariaDB","permalink":"http://www.dwxu.me/tags/MariaDB/"},{"name":"Replication","slug":"Replication","permalink":"http://www.dwxu.me/tags/Replication/"}]},{"title":"Spring Boot 应用输出 Mybatis SQL 语句","slug":"spring-boot-mybatis-sql","date":"2018-05-31T13:58:22.000Z","updated":"2018-05-31T14:04:52.708Z","comments":true,"path":"2018/05/31/spring-boot-mybatis-sql/","link":"","permalink":"http://www.dwxu.me/2018/05/31/spring-boot-mybatis-sql/","excerpt":"","text":"1. 在 logback.xml 增加配置123456789101112131415161718&lt;configuration scan=\"true\"&gt; &lt;!-- 输出到控制台 --&gt; &lt;appender name=\"stdout\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"&gt; &lt;pattern&gt; %d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;40&#125; - %msg%n &lt;/pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"stdout\" /&gt; &lt;/root&gt; &lt;logger name=\"com.foo.component.mapper\" level=\"DEBUG\"&gt; &lt;appender-ref ref=\"stdout\"/&gt; &lt;/logger&gt;&lt;/configuration&gt; logger 节点 name 属性的值为 Mybatis Mapper 接口所在包路径； 示例中将日志输出到标准输出（控制台）中； 2. 重启应用3. 进行数据库查询，可以看到控制台输出相关 SQL 查询日志12309:07:58.029 [http-nio-8030-exec-1] DEBUG l._.p.c.mapper.UserSiteMapper.count - ==&gt; Preparing: select count(id) from platform_user_site WHERE user_id = ? 09:07:58.029 [http-nio-8030-exec-1] DEBUG l._.p.c.mapper.UserSiteMapper.count - ==&gt; Parameters: 3(Long)09:07:58.032 [http-nio-8030-exec-1] DEBUG l._.p.c.mapper.UserSiteMapper.count - &lt;== Total: 1","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.dwxu.me/categories/Spring/"}],"tags":[{"name":"Spring-Boot","slug":"Spring-Boot","permalink":"http://www.dwxu.me/tags/Spring-Boot/"},{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.dwxu.me/tags/Mybatis/"},{"name":"Logback","slug":"Logback","permalink":"http://www.dwxu.me/tags/Logback/"}]},{"title":"Spring Cloud 多服务/多实例 Session 共享","slug":"spring-cloud-session","date":"2018-05-29T14:50:16.000Z","updated":"2018-05-29T16:06:11.551Z","comments":true,"path":"2018/05/29/spring-cloud-session/","link":"","permalink":"http://www.dwxu.me/2018/05/29/spring-cloud-session/","excerpt":"","text":"项目中，前后端分离，后端使用 Spring Cloud 管理多个微服务和多个实例，使用 Zuul 实现 API Gateway （反向代理）供前端请求/访问。前后端分离，需要做前端请求的权限认证，即鉴权，由于我们的项目后端提供的接口仅供前端请求，非对外公共接口，因此不考虑搭建统一认证（如 OAUTH 2.0）中心走那么复杂的认证过程，此外考虑过做简单 JWT 的认证，但由于缺点比较明显，如注销/退出问题，在 JWT 过期之前无法/难以作废已颁发的令牌，最后决定用回简单的 Http Session 认证/验证，用户注销/退出时清除 Session 中记录的用户/权限信息，关闭浏览器后 Session 自动失效。那么需要解决的问题，是 多服务 或者 服务多实例 间的 Session 共享问题，Spring 本身提供了 Spring-session 方案和策略（常用为 Cookie 和 Header 方式），配合 Redis 即可实现 Session 的共享： 应用 pom.xml 引入以下依赖： 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt; &lt;version&gt;$&#123;redis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-session.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 应用 application.yml 添加 Redis 配置： 12345spring: redis: host: 192.168.1.221 port: 6379 password: password 应用 Session 配置（代码），使用 Cookie 方式： 1234567@EnableRedisHttpSession(redisFlushMode = RedisFlushMode.IMMEDIATE)public class HttpSessionConfig &#123; @Bean public HttpSessionStrategy httpSessionStrategy() &#123; return new CookieHttpSessionStrategy(); &#125;&#125; 然而存在问题，前端请求经过 API Gateway，Zuul 没有把原始请求的 Cookie（Header）转发到服务（应用），因此应用每次获取的 Session 都不一样（每次都生成新的 Session）。因此需要在 API Gateway （Zuul）这一层增加处理： 按上述过程在 API Gateway 应用中开启 Session 共享； 实现一个 ZuulFilter 过滤器，将 Cookie（因为我们使用的是 Cookie 共享策略）写入转发的请求头部中：1234567891011121314151617181920212223242526272829@Componentpublic class ForwardCookieFilter extends ZuulFilter &#123; @Autowired private SessionRepository repository; @Override public String filterType() &#123; return \"pre\"; &#125; @Override public int filterOrder() &#123; return 0; &#125; @Override public Object run() &#123; RequestContext context = RequestContext.getCurrentContext(); HttpSession httpSession = context.getRequest().getSession(); context.addZuulRequestHeader(\"Cookie\", \"SESSION=\" + httpSession.getId()); return null; &#125; @Override public boolean shouldFilter() &#123; return true; &#125;&#125; 请求到达服务/应用时，Spring-session 共享即可生效，简单测试： 在 Controller 中读写 Session（Attribute）： 123456789101112131415@RestController@RequestMapping(\"/\")public class IndexController &#123; @RequestMapping(\"foo\") public void foo(HttpServletRequest request) throws IOException &#123; System.out.println(request.getSession().getId()); request.getSession().setAttribute(\"foo\", \"bar\"); &#125; @RequestMapping(\"bar\") public void bar(HttpServletRequest request) throws IOException &#123; System.out.println(request.getSession().getId()); System.out.println(\"foo: \" + request.getSession().getAttribute(\"foo\")); &#125;&#125; 部署两个实例： 访问 /foo，其中一个实例会将 “bar” 写入 Session 的 “foo” 属性中； 多次访问 /bar，可以看到两个实例控制台交替输出中，sessionId 保持不变，正确输出写入的 Session 属性值：123f4fa81c-ecb4-41b4-a551-daab0f3198aafoo: bar 另外，网上有其他处理的方法，如修改 Zuul 和 Hystrix 的配置，没有实际验证过，不知是否有效。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.dwxu.me/categories/Spring/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.dwxu.me/tags/Redis/"},{"name":"Spring-Cloud","slug":"Spring-Cloud","permalink":"http://www.dwxu.me/tags/Spring-Cloud/"},{"name":"Spring-Session","slug":"Spring-Session","permalink":"http://www.dwxu.me/tags/Spring-Session/"}]},{"title":"Linux系统端口范围限制","slug":"linux-port","date":"2018-05-27T01:36:19.000Z","updated":"2018-05-27T02:35:41.206Z","comments":true,"path":"2018/05/27/linux-port/","link":"","permalink":"http://www.dwxu.me/2018/05/27/linux-port/","excerpt":"","text":"最近参与的项目中，使用 Apche Storm 实时消费/处理 Kafka 消息，但提交执行 Topology 时，经常发现启动（各个工作节点正常工作）很久，查看工作节点的相关日志（${STORM_HOME}/logs/workers-artifacts/ 目录下），经常发现有大量以下错误日志在滚动输出：12018-05-24 15:30:00.453 o.a.s.m.n.Client [ERROR] connection attempt 26 to Netty-Client-cdh5/xxx.xxx.xxx.xxx:6714 failed: java.net.ConnectException: Connection refused: cdh5/xxx.xxx.xxx.xxx:6714 从日志初步看，是工作进程尝试与其他工作进程进行通信建立连接时被拒绝，很大可能是工作进程还没有启动完成（监听相关端口，如上述日志中 cdh5 的 6714 端口）。正常来说，程序监听空闲端口启动是很快的，除非是端口被占用了，一直在等待端口释放。我们的 Storm 集群中有多个工作节点共一个百多工作进程（worker），其中某些节点上的某些工作进程监听端口失败一直在重试，节点工作进程间通信失败，整个集群启动耗时很长甚至无法完成启动进行工作。我们 Storm 的工作进程端口列表（${STORM_HOME}/conf/storm.yaml 配置 supervisor.slots.ports 指定）为 6700 - 6731，查看 Linux 系统预留源端口：12$ cat /proc/sys/net/ipv4/ip_local_port_range1024 65000 系统预留了 1024 - 65000 端口作为服务端口，也就是说 TCP/IP协议栈会从 1024 - 65000 中随机选取端口作为源与其他服务建立连接进行通信，而我们 Strom 的工作进程端口列表正好包含在这个范围内，但程序停止时，释放的端口可能被占用了，导致下次启动异常，因此需要调整该配置： 修改 /etc/sysctl.conf 中 net.ipv4.ip_local_port_range 配置的范围，使其不包含我们需要的 6700 - 6731（如 6732 - 65000）； 重启系统或者执行 sysctl -p 让配置生效； 注意端口范围不要超过 1024 和 65535，1024 以下系统使用，65535 以上设置会会提示失败； 经过以上的操作，我们再次向 Strom 集群提交 Topology 后启动便很快了，另外从 Storm UI 监控界面上也发现消费速度有很大的提升（估计也跟端口开放/竞争有关）。 另外，ip_local_port_range 是范围配置，以上修改使得系统可用端口量减少了，但服务器需要消耗大量端口号时可能会存在瓶颈。可与以下配置配合： ip_local_reserved_ports：TCP/IP协议栈从 ip_local_port_range 中随机选取源端口时，会排除ip_local_reserved_ports 中定义的端口，同样在 /etc/sysctl.conf 中配置； 如以上修改按以下配置（不改动 ip_local_port_range ）：1net.ipv4.ip_local_reserved_ports = 6700-6731 12345678910111213141516# sysctl -pnet.ipv4.ip_forward = 0net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0kernel.sysrq = 0kernel.core_uses_pid = 1net.ipv4.tcp_syncookies = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.shmmax = 68719476736kernel.shmall = 4294967296net.ipv4.ip_local_reserved_ports = 6700-6731# cat /proc/sys/net/ipv4/ip_local_port_range1024 65000# cat /proc/sys/net/ipv4/ip_local_reserved_ports6700-6731","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.dwxu.me/categories/Linux/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://www.dwxu.me/tags/运维/"}]},{"title":"Linux系统使用 iostat 命令监视磁盘设备活动情况","slug":"linux-iostat","date":"2018-05-24T14:10:10.000Z","updated":"2018-05-27T02:35:09.960Z","comments":true,"path":"2018/05/24/linux-iostat/","link":"","permalink":"http://www.dwxu.me/2018/05/24/linux-iostat/","excerpt":"","text":"最近在排查 MariaDB 主从数据库数据同步/复制延迟问题，使用 Linux 系统的 iostat 查看服务器磁盘设备的活动情况，发现瓶颈在于磁盘的I/O，一般而言，大量数据读写频繁的情况下，最终磁盘I/O都会成为瓶颈。 1. 使用说明 查看 CPU 和磁盘 I/O 相关的统计信息 指令格式： 123456[51la_dev@db2 ~]$ iostat --helpUsage: iostat [ options ] [ &lt;interval&gt; [ &lt;count&gt; ] ]Options are:[ -c ] [ -d ] [ -N ] [ -n ] [ -h ] [ -k | -m ] [ -t ] [ -V ] [ -x ] [ -y ] [ -z ][ -j &#123; ID | LABEL | PATH | UUID | ... &#125; [ &lt;device&gt; [...] | ALL ] ][ &lt;device&gt; [...] | ALL ] [ -p [ &lt;device&gt; [,...] | ALL ] ] 主要参数说明： -c：显示CPU使用情况 -d：显示磁盘使用情况 -k：以 KB 为单位显示 -m：以 M 为单位显示 -N：显示磁盘阵列(LVM) 信息 -n：显示NFS 使用情况 -p[磁盘]：显示磁盘和分区的情况 -t：显示终端和CPU的信息 -x：显示详细信息 -V：显示版本信息 2. 使用实例 输出信息说明： 首行：系统/服务器相关信息 avg-cpu：cpu 状态信息 rrqm/s：每秒合并读操作的次数 wrqm/s：每秒合并写操作的次数 r/s：每秒读操作的次数 w/s： 每秒写操作的次数 rMB/s：每秒读取的MB字节数 wMB/s：每秒写入的MB字节数 avgrq-sz：平均每个 I/O 操作的扇区数，即所有请求的平均大小，以扇区（512字节）为单位 avgqu-sz：平均 I/O 请求队列长度 await：平均每个 I/O 所需要的时间，包括在队列等待的时间，也包括磁盘控制器处理本次请求的有效时间（毫秒） r_wait：每个读操作平均所需要的时间，不仅包括硬盘设备读操作的时间，也包括在内核队列中的时间（毫秒） w_wait：每个写操平均所需要的时间，不仅包括硬盘设备写操作的时间，也包括在队列中等待的时间（毫秒） svctm：平均每次设备I/O操作的服务时间 (毫秒) %util：工作时间或者繁忙时间占总时间的百分比 简单分析以上截图： 服务器有 48 个逻辑 CPU，而且很空闲（93.36% 的空闲），性能是比较强 sde 磁盘/设备的写操作十分频繁（每秒超过 1000 次），读操作平均等待时间超过 1000 毫秒，尤其是 %util 到达 100%（没有空闲时间），很容易（或已经）导致性能受限，成为相关任务的瓶颈。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.dwxu.me/categories/Linux/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://www.dwxu.me/tags/运维/"}]},{"title":"Java自动装箱和拆箱","slug":"java-boxing","date":"2018-05-22T14:10:15.000Z","updated":"2018-05-22T14:47:11.607Z","comments":true,"path":"2018/05/22/java-boxing/","link":"","permalink":"http://www.dwxu.me/2018/05/22/java-boxing/","excerpt":"","text":"毫无疑问，自动装箱和自动拆箱是 Java 语言里使用最多的语法糖。以 Integer 为例：12345public static void main(String[] args) &#123; Integer foo = 1; List&lt;Integer&gt; bar = Arrays.asList(1, 2, 3, 4); Integer[] baz = &#123;1, 2, 3, 4&#125;;&#125; 编译为 Class 文件后反编译：12345public static void main(String[] var0) &#123; Integer var1 = Integer.valueOf(1); List var2 = Arrays.asList(Integer.valueOf(1), Integer.valueOf(2), Integer.valueOf(3), Integer.valueOf(4)); Integer[] var10000 = new Integer[]&#123;Integer.valueOf(1), Integer.valueOf(2), Integer.valueOf(3), Integer.valueOf(4)&#125;;&#125; 自动装箱和拆箱是 JDK1.5 的新特性，之前都是手动进行包装类的装箱和拆箱：123int foo = 1; // 基本数据类型intInteger bar = new Integer(foo); // 手动装箱int baz = bar.intValue(); // 手动拆箱 JDK1.5 之后自动进行装箱和拆箱：123Integer foo = 10; // 自动装箱int bar = foo; // 自动拆箱System.out.println(foo--); // 输出10, 计算时的自动拆箱 另外，观察以下程序：123456789public static void main(String[] args) &#123; Integer a = 95; Integer b = 95; System.out.println(\"a == b: \" + (a == b)); Integer c = 295; Integer d = 295; System.out.println(\"c == d: \" + (c == d));&#125; 输出结果为：12a == b: truec == d: false 原因是在自动装箱的时候，[-128, 127] 内的值被装箱成 Integer 对象存在内存中（Cache），可以被重用，“ == ” 比较的是对象的内存地址，因此 a 和 b 实际上是同一个对象，比较结果自然是 true，而超出以上范围的数值装箱后的对象并不会被重用，那么就相当于创建两个对象，比较的结果自然是false。每种基本数据类型都有对应的包装类，如下： 基本数据类型 包装类 int Integer char Character float Float double Double byte Byte short Short long Long boolean Boolean","categories":[{"name":"Java","slug":"Java","permalink":"http://www.dwxu.me/categories/Java/"}],"tags":[{"name":"语法糖","slug":"语法糖","permalink":"http://www.dwxu.me/tags/语法糖/"}]},{"title":"同一手机号注册多个 Gmail 邮箱","slug":"gmail-register","date":"2018-05-21T13:37:18.000Z","updated":"2018-05-24T14:54:28.964Z","comments":true,"path":"2018/05/21/gmail-register/","link":"","permalink":"http://www.dwxu.me/2018/05/21/gmail-register/","excerpt":"","text":"由于之前注册的 Gmail 邮箱地址包含个人信息（十分建议申请邮箱地址时慎用个人信息，如生日等）并且不太正式，因此想另外申请一个邮箱地址，然而目前一个手机号注册只能注册一个账号，无法直接重新申请：尝试了多种方式进行注册后，发现可以使用 Chrome 浏览器 注册成功： 打开 设置 页面，点击 登录 CHROME，在弹出来的对话框中，点击 更多选项，选择 创建新账号： 按提示填写 姓氏 和 姓名 后，进入发送验证码页面，国家/地区 选择 HK，电话号码前面增加 +86： 点击 下一步，即可收到验证码短信： 之后根据提示填写邮箱地址完成注册 旧的邮箱可能绑定过其他网站或者系统，也需要查看相关邮件，可以使用新的邮箱代收旧邮箱的邮件，在 Gmail 邮箱界面 设置 - 账号和导入 - 查收其他账号的邮件 中进行设置，具体操作可点击 了解详情 查看。","categories":[{"name":"备忘","slug":"备忘","permalink":"http://www.dwxu.me/categories/备忘/"}],"tags":[{"name":"Gmail","slug":"Gmail","permalink":"http://www.dwxu.me/tags/Gmail/"}]},{"title":"Java泛型与类型擦除","slug":"java-generics","date":"2018-05-19T09:26:40.000Z","updated":"2018-05-22T14:46:07.196Z","comments":true,"path":"2018/05/19/java-generics/","link":"","permalink":"http://www.dwxu.me/2018/05/19/java-generics/","excerpt":"","text":"泛型是 JDK1.5 的一项新增特性，本质是参数化类型的应用，即所操作的数据类型被指定为一个参数，可以用在类、接口和方法的创建中，分别称为泛型类、泛型接口和泛型方法： 泛型接口： 1通过类实现泛型接口时指定泛型 K 和 V 的具体类型，如 java.util 包中的 Map&lt;K, V&gt; ； 泛型类： 1编译器无法知道 K 和 V 的具体类型，只有运行时才真正根据类型来构造和分配内存，如 java.util 包中的 HashMap&lt;K,V&gt; ； 泛型方法：泛型方法返回值前加一个、等来声明这是一个泛型方法，如 12345678910111213public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; ... public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; ... public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; ...&#125; 实际上，Java中 的泛型与 C++/C# 的中泛型实现不同，只在程序源码中存在，在编译后的字节码文件中，就已经替换为原生类型（也称为裸类型，如 Map&lt;K, V&gt; 即为 Map），并且在相应的地方插入了强制类型转换的代码，如： 123456789public static void main(String[] args) &#123; Map&lt;String, String&gt; data = new HashMap&lt;String, String&gt;(); data.put(\"foo\", \"foo\"); data.put(\"bar\", \"bar\"); data.put(\"baz\", \"baz\"); System.out.println(data.get(\"foo\")); System.out.println(data.get(\"bar\")); System.out.println(data.get(\"baz\"));&#125; 编译为 Class 文件后反编译：123456789public static void main(String[] paramArrayOfString) &#123; HashMap localHashMap = new HashMap(); localHashMap.put(\"foo\", \"foo\"); localHashMap.put(\"bar\", \"bar\"); localHashMap.put(\"baz\", \"baz\"); System.out.println((String)localHashMap.get(\"foo\")); System.out.println((String)localHashMap.get(\"bar\")); System.out.println((String)localHashMap.get(\"baz\"));&#125; 这种类型擦除的方式实现的泛型支持，只是作为一种语法糖来方便程序员的代码开发，提高效率和语法的严谨性，减少编码出错的机会，但并没有提供底层实质性的功能改进，因此 Java 的泛型支持实现一直存在争议和批评，例如由于 List&lt;String&gt; 和 List&lt;Integer&gt; 擦除后是同一类型（List），无法实现重载（实际上，两个方法如果返回值类型不同，使用 Sun JDK 1.6 的 javac 也能编译成功）。","categories":[{"name":"Java","slug":"Java","permalink":"http://www.dwxu.me/categories/Java/"}],"tags":[{"name":"语法糖","slug":"语法糖","permalink":"http://www.dwxu.me/tags/语法糖/"},{"name":"泛型","slug":"泛型","permalink":"http://www.dwxu.me/tags/泛型/"}]},{"title":"高并发下多站点在线访问实时统计","slug":"online-statistics","date":"2018-05-16T15:20:09.000Z","updated":"2018-05-16T15:24:15.382Z","comments":true,"path":"2018/05/16/online-statistics/","link":"","permalink":"http://www.dwxu.me/2018/05/16/online-statistics/","excerpt":"","text":"一、业务背景 实时统计多个站点的在线独立访问情况； 统计的时间范围为 10/15/30 分钟； 所有站点每秒累计约 10w 的 pv； 二、解决思路 按客户端 IP+SessionId 区分独立访问； 将在线访问信息（站点ID、IP、Session Id、访问时间等）写入 Kafka 集群； Storm(集群) 实时消费 Kafka 在线访问信息/消息，合并访问写入 Redis； 上层应用从 Redis 获取各站点 10/15/30 分钟内的独立访问数据进行计算并展示； 三、详细设计1. redis 数据结构设计 将每分钟的站点数据写入一个 Hash 集合（过期时间为 30 分钟），key 为 online:{comId}:{minute}，其中 {comId} 为站点ID，{minute} 为在线时间的分钟字段（0-59）； 集合下的元素结构为：field - {ip}:{sessionId}（独立访问），value - 该独立访问一分钟内的请求/响应次数，通过 hincrby 指令递增； 2. 数据统计 统计范围为当前 10/15/30 分钟内； 通过站点ID及当前时间从 redis 中读取该站点 30 分钟内的数据集合，例如站点ID为1，查询时间为 9点33分钟，则从 redis 读取 online:1:33 - online:1:3 的数据集合； 合并数据集合的 key（{ip}:{sessionId}），即去重，即可得到指定时间范围内的在线访问数； 3. 说明 数据写入 Redis 频繁，需要优先考虑写入耗时和内存的问题，因此通过 hincrby 和 expired 这两个时间复杂度为 O(1) 的指令来快速写入在线数据； 每个站点的数据集合过期时间为 30 分钟（根据请求时间计算过期的时间戳），因此一个站点最多同时存在 30 个数据集合，过期的集合由 Redis 自动清理，无需再自行清理； 每个集合的有效数据实际为 field 的部分，记录每分钟的独立访问，接口在获取数据进行统计时，直接取出 field 的 Set 集合进行自动合并即可； 四、线上情况 Redis 单机/单实例； 30分钟内活跃的站点约 1.5w 个，两个小时内监控 Redis，redis 总内存占用稳定在 5.5G 以下（较上线此统计前多占用 1G 内存），数据集合能够正常过期并被 redis 清理； 应用 0.3s 内完成统计访问最频繁/数据量最大的站点的各时段内在线访问情况，当然跟服务器性能比较好也有关系；","categories":[{"name":"解决方案","slug":"解决方案","permalink":"http://www.dwxu.me/categories/解决方案/"}],"tags":[{"name":"实时统计","slug":"实时统计","permalink":"http://www.dwxu.me/tags/实时统计/"},{"name":"Redis","slug":"Redis","permalink":"http://www.dwxu.me/tags/Redis/"}]},{"title":"各大搜索引擎来路referer头部及搜索关键字字段","slug":"search-engine-referer","date":"2018-05-15T12:25:00.000Z","updated":"2018-05-15T12:38:28.993Z","comments":true,"path":"2018/05/15/search-engine-referer/","link":"","permalink":"http://www.dwxu.me/2018/05/15/search-engine-referer/","excerpt":"","text":"1. 百度搜索： PC端： referer： 1https://www.baidu.com/link?url=gZRk-i0rKd2zEpXr6gLWgcMaB6gj49Qh0SRhVyeD1TG&amp;wd=&amp;eqid=e0224cf50000f590000000065ac98dee 关键字字段：wd（无实际值） 移动端： referer： 1https://m.baidu.com/from=0/bd_page_type=1/ssid=0/uid=0/pu=usm%401%2Csz%40320_1001%2Cta%40iphone_2_6.0_3_537/baiduid=EDC0F469B2C8C28ED6153A8DFE7B0F35/w=0_10_/t=iphone/l=1/tc?ref=www_iphone&amp;lid=9293408228010889187&amp;order=1&amp;fm=alop&amp;dict=-1&amp;tj=www_sitelink_normal_1_0_10_title&amp;wd=&amp;eqid=80f8d18b77481000100000005ac98e54&amp;w_qd=IlPT2AEptyoA_yjkTUugn4fHR5kW&amp;tcplug=1&amp;sec=28899&amp;di=6b8e30a65323dcbb&amp;bdenc=1&amp;tch=124.0.206.178.0.0&amp;nsrc=IlPT2AEptyoA_yixCFOxXnANedT62v3IEQGG_8kJLDKv7JuV&amp;clk_info=%7B%22srcid%22%3A1539%2C%22tplname%22%3A%22www_sitelink_normal%22%2C%22t%22%3A1523158616510%2C%22xpath%22%3A%22div-a-h3-em%22%7D 关键字字段：wd（无实际值） 2. 搜狗搜索（soso 搜索）： PC端： referer： 1https://www.sogou.com/link?url=DSOYnZeCC_oowgX7OeX6FW4YafSeot-j 关键字字段：无 移动端： referer： 1https://m.sogou.com/web/searchList.jsp?uID=vU0WMAQthy-ORLar&amp;v=5&amp;from=index&amp;w=1274&amp;t=1523158841365&amp;s_t=1523158844479&amp;s_from=index&amp;keyword=51la%E7%BB%9F%E8%AE%A1&amp;pg=webSearchList&amp;sourceid=sugg&amp;sugoq=&amp;sugn=0&amp;suguuid=fa153a85-07bb-4afa-bb07-69d3775d9966&amp;sugsuv=AAHV9fA6HwAAAAqRK1G8bQ0A1wA%3D&amp;sugtime=1523158844484 1https://wap.sogou.com/web/searchList.jsp?uID=vU0WMAQthy-ORLar&amp;v=5&amp;from=index&amp;w=1274&amp;t=1523158841365&amp;s_t=1523158844479&amp;s_from=index&amp;keyword=51la%E7%BB%9F%E8%AE%A1&amp;pg=webSearchList&amp;sourceid=sugg&amp;sugoq=&amp;sugn=0&amp;suguuid=fa153a85-07bb-4afa-bb07-69d3775d9966&amp;sugsuv=AAHV9fA6HwAAAAqRK1G8bQ0A1wA%3D&amp;sugtime=1523158844484 关键字字段：keyword（有实际值） 3. 360 搜索（360好搜）： PC端： referer： 1http://www.so.com/link?m=afEPOwxb%2BqdAts7rzNmmh%2F2cxMIM5669zqvLn1I5nPYjRlp8haa0nn%2FWJfYFNGvfzb4XdzUBb5wCnL2um08mnoi%2Bsge9ZjqTN referer 关键字字段：无 移动端： referer： 1https://m.so.com/s?q=51la%E7%BB%9F%E8%AE%A1&amp;src=msearch_next_input&amp;sug_pos=&amp;sug=&amp;srcg=home_next 关键字字段：q（有实际值） 4. 谷歌搜索： PC端： referer： 1https://www.google.co.jp/（每个国家/地区的域名后缀不同，如 co.jp - 日本，hk - 香港，de - 德国） referer 关键字字段：无 移动端： referer： 1https://www.google.com/ 关键字字段：无 5. 神马搜索： PC端：无 移动端： referer： 1https://zm12.sm-tc.cn/?src=l4uLj8XQ0IiIiNHKztGTntA%3D&amp;uid=b64442e88b6decc4f6ade0bf131e6af0&amp;hid=0828a13d4a51cd539610a6c5a2e50f36&amp;pos=1&amp;cid=9&amp;time=1523160482592&amp;from=click&amp;restype=1&amp;pagetype=0400000000000004&amp;bu=web&amp;query=51la%E7%BB%9F%E8%AE%A1&amp;mode=&amp;v=1&amp;province=%E5%B9%BF%E4%B8%9C%E7%9C%81&amp;city=%E5%B9%BF%E5%B7%9E%E5%B8%82&amp;uc_param_str=dnntnwvepffrgibijbprsvdsdichei 关键字字段：query（有实际值），host 为 zm12.sm-tc.cn 6. BingLive（微软Bing搜索）： PC端： referer： 1https://www.bing.com/ 关键字字段：无 移动端： referer： 1https://www.bing.com/ 关键字字段：无 7. 有道/网易搜索：目前仅为词典搜索","categories":[{"name":"互联网","slug":"互联网","permalink":"http://www.dwxu.me/categories/互联网/"}],"tags":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"http://www.dwxu.me/tags/搜索引擎/"}]},{"title":"Hello World","slug":"Hello-World","date":"2018-05-14T13:31:51.000Z","updated":"2018-05-14T15:32:08.106Z","comments":true,"path":"2018/05/14/Hello-World/","link":"","permalink":"http://www.dwxu.me/2018/05/14/Hello-World/","excerpt":"","text":"你好，世界！ 不客观的说，自己也不算懒，但也不知道拖延了多久，总算是把个人博客的样子给整出来了。 基于 GitHub + Hexo 搭建，找了一套相对简洁的页面模板，稍微加以改造，便是现在这个样子，还算满意。 年后转到公司新的部门后，一直比较忙，期间也解决了一些大大小小的问题，在业务和技术方面也算有所收获，也一直想着找机会和时间总结并记录下来，于是乎又想起来久违的个人博客计划，花了两个晚上失落，过程比较顺利。 那么，之后要花更多的时间和精力，充实博客，充实自己！ 晚安！","categories":[{"name":"日记","slug":"日记","permalink":"http://www.dwxu.me/categories/日记/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.dwxu.me/tags/日记/"}]}]}